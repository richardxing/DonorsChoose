{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Richard\\AppData\\Local\\conda\\conda\\envs\\data_science\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train=pd.read_csv(\"C:/Users/Richard/Datasets/DonorsChoose/train.csv\")\n",
    "test=pd.read_csv(\"C:/Users/Richard/Datasets/DonorsChoose/test.csv\")\n",
    "resources=pd.read_csv(\"C:/Users/Richard/Datasets/DonorsChoose/resources.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create these features for each proposal:\n",
    "- total price\n",
    "- highest single item price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resources['total_price']=resources['price']*resources['quantity'];\n",
    "                    #if as_index=True by default, these are series; otherwise, it returns a DataFrame\n",
    "#rg2=resources.groupby(by='id')['total_price'].agg('sum')#same\n",
    "rg1=resources.groupby(by='id', as_index=False)['total_price'].sum();\n",
    "rg2=resources.groupby(by='id',as_index=False)['price'].max();\n",
    "rg2.rename({'price':'highest_single_item_price'},axis='columns',inplace=True);#rename column name\n",
    "rg12=pd.merge(rg1,rg2,how='inner',on='id');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join the tables got from resources.csv & train.csv; resources.csv & test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1=pd.merge(train,rg12,how='left',on='id')\n",
    "test1=pd.merge(test,rg12,how='left',on='id')\n",
    "\n",
    "train1['project_submitted_datetime']=pd.to_datetime(train1['project_submitted_datetime'])\n",
    "train1['project_submitted_datetime']=train1['project_submitted_datetime'].dt.date\n",
    "test1['project_submitted_datetime']=pd.to_datetime(test1['project_submitted_datetime'])\n",
    "test1['project_submitted_datetime']=test1['project_submitted_datetime'].dt.date\n",
    "y_train1=train1['project_is_approved']\n",
    "X_train1=train1.drop(['project_is_approved'],axis=1)\n",
    "X_test1=test1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reasons not to use sub categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Applied Sciences, Warmth, Care & Hunger',\n",
       " 'Civics & Government, Extracurricular',\n",
       " 'Civics & Government, Music',\n",
       " 'Civics & Government, Nutrition Education',\n",
       " 'Civics & Government, Other',\n",
       " 'Civics & Government, Performing Arts',\n",
       " 'Civics & Government, Team Sports',\n",
       " 'Civics & Government, Warmth, Care & Hunger',\n",
       " 'Community Service, ESL',\n",
       " 'Community Service, Nutrition Education',\n",
       " 'Community Service, Team Sports',\n",
       " 'ESL, Economics',\n",
       " 'ESL, Team Sports',\n",
       " 'ESL, Warmth, Care & Hunger',\n",
       " 'Economics, Foreign Languages',\n",
       " 'Economics, Health & Life Science',\n",
       " 'Economics, Music',\n",
       " 'Economics, Other',\n",
       " 'Economics, Team Sports',\n",
       " 'Extracurricular, Foreign Languages',\n",
       " 'Extracurricular, Nutrition Education',\n",
       " 'Extracurricular, Social Sciences',\n",
       " 'Financial Literacy, Performing Arts',\n",
       " 'Foreign Languages, Gym & Fitness',\n",
       " 'Foreign Languages, Team Sports',\n",
       " 'Gym & Fitness, Parent Involvement',\n",
       " 'Gym & Fitness, Warmth, Care & Hunger',\n",
       " 'Health & Life Science, Warmth, Care & Hunger',\n",
       " 'History & Geography, Warmth, Care & Hunger',\n",
       " 'Nutrition Education, Parent Involvement',\n",
       " 'Nutrition Education, Performing Arts',\n",
       " 'Nutrition Education, Social Sciences',\n",
       " 'Parent Involvement, Team Sports',\n",
       " 'Parent Involvement, Warmth, Care & Hunger',\n",
       " 'Social Sciences, Warmth, Care & Hunger'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(X_test1['project_subject_subcategories'].unique())^set(X_train1['project_subject_subcategories'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test1['project_subject_subcategories'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract complete categorical values for creating one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_prefix=list(X_train1['teacher_prefix'].dropna(axis=0, how='any').unique())\n",
    "complete_state=list(X_train1['school_state'].unique())\n",
    "complete_grade=list(X_train1['project_grade_category'].unique())\n",
    "complete_category=list(X_train1['project_subject_categories'].unique())#51 categories\n",
    "#complete_sub_category=list(X_train1['project_subject_subcategories'].unique())#407 sub-categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class add_features(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Takes in dataframe, extracts road name column, outputs average word length\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass #self.vars = vars  # e.g. pass in a column name to extract\n",
    "\n",
    "    def convert_log(self, previous_proposals):#passed in is a Series?no datapoint\n",
    "        #return np.mean([len(word) for word in name.split()])\n",
    "        result=np.log(1+float(previous_proposals))\n",
    "        #print(result)\n",
    "        return result\n",
    "\n",
    "    def transform(self, df, y=None):\n",
    "        \"\"\"The workhorse of this feature extractor\"\"\"\n",
    "        \"\"\"features about reject pressure. project viewers need to reject certain percentage\n",
    "        of proposals due to limited resources. \n",
    "        This is probably a better way to use datetime info\"\"\"\n",
    "        pd.options.mode.chained_assignment = None#ignore SettingWithCopyWarning because it's false positive, everything I do here is on a copy and I return a copy. if I change the names of df to df1,df2 etc, the warning should be gone.\n",
    "\n",
    "        df.loc[:,'reject_pressure_by_funds']=df.groupby('project_submitted_datetime')['total_price'].transform(lambda x: x.sum())\n",
    "        df.loc[:,'reject_pressure_by_projects']=df.groupby('project_submitted_datetime')['total_price'].transform(lambda x: x.count())\n",
    "        df.loc[:,'log_previously_posted_projects']=df['teacher_number_of_previously_posted_projects'].apply(self.convert_log)\n",
    "        #create DataFrames that contain categorical information\n",
    "        prefix = pd.get_dummies(df['teacher_prefix'],drop_first=False)\n",
    "        state=pd.get_dummies(df['school_state'],drop_first=False)\n",
    "        grade= pd.get_dummies(df['project_grade_category'],drop_first=False)\n",
    "        category= pd.get_dummies(df['project_subject_categories'],drop_first=False)\n",
    "        #sub_category=pd.get_dummies(df['project_subject_subcategories'],drop_first=False)\n",
    "        missing_cols_main=set(complete_prefix+complete_state+complete_grade+complete_category)-(set(list(prefix))|set(list(state))|set(list(grade))|set(list(category)))\n",
    "        #missing_cols_extra=set(complete_sub_category)-set(list(sub_category))\n",
    "        #set(complete_category)&set(complete_sub_category) not empty\n",
    "        #print (missing_cols_main)\n",
    "        #print (missing_cols_extra)\n",
    "        df=pd.concat([df,prefix],axis=1)\n",
    "        df=pd.concat([df,state],axis=1)\n",
    "        df=pd.concat([df,grade],axis=1)\n",
    "        df=pd.concat([df,category],axis=1)\n",
    "        #df=pd.concat([df,sub_category],axis=1)\n",
    "        for c1 in missing_cols_main:\n",
    "            df.loc[:,c1] = 0\n",
    "        #for c2 in missing_cols_extra:\n",
    "        #    df.loc[:,c2] = 0\n",
    "        #del prefix,state,grade,category#,sub_category\n",
    "        #del missing_cols_main\n",
    "        #del missing_cols_extra\n",
    "\n",
    "        to_be_dropped_sure=['id',\n",
    "         'teacher_id',\n",
    "         'teacher_prefix',\n",
    "         'school_state',\n",
    "         'project_submitted_datetime',\n",
    "         'project_grade_category',\n",
    "         'project_subject_categories',\n",
    "         'project_subject_subcategories',\n",
    "         'project_title',\n",
    "         'project_essay_1',\n",
    "         'project_essay_2',\n",
    "         'project_essay_3',\n",
    "         'project_essay_4',\n",
    "         'project_resource_summary',\n",
    "         'teacher_number_of_previously_posted_projects']\n",
    "        to_be_dropped=to_be_dropped_sure#+complete_prefix+complete_state+complete_grade+complete_category#+complete_sub_category\n",
    "        #print(df.drop(to_be_dropped,axis=1).head(1))\n",
    "        df.drop(to_be_dropped,axis=1,inplace=True)\n",
    "        return df\n",
    "\n",
    "    def fit(self, df, y=None,**fit_params):\n",
    "        \"\"\"Returns `self` unless something different happens in train and test\"\"\"\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Richard\\AppData\\Local\\conda\\conda\\envs\\data_science\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import LinearRegression,Lasso\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import cross_val_score,StratifiedKFold,ShuffleSplit\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_learner=xgb.XGBRegressor #eg. xgb_learner(max_depth=3, n_estimators=300, learning_rate=0.05) in the pipeline\n",
    "simplest_learner=LinearRegression\n",
    "lasso=Lasso\n",
    "steps=[('features', FeatureUnion([\n",
    "    ('add_features', add_features()) # can pass in either a pipeline or a transformer#\n",
    "    ])),('scaler',StandardScaler()),('estimator',xgb_learner())]\n",
    "pipeline=Pipeline(steps)#"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cv1=StratifiedKFold(n_splits=5, shuffle=True, random_state=1238462)\n",
    "cv2=ShuffleSplit(n_splits=5, random_state=938475)\n",
    "#score=cross_val_score(pipeline,train1.drop(['project_is_approved'],axis=1),train1['project_is_approved'],cv=cv2,scoring='roc_auc')\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = dict(estimator__max_depth=[3],\n",
    "                 estimator__n_estimators=[500],\n",
    "                 estimator__learning_rate=[0.01]) #(name_by_me__parameter=[100,200,300],...)\n",
    "#>>> dict(sape=4139, guido=4127, jack=4098)\n",
    "#{'sape': 4139, 'jack': 4098, 'guido': 4127}\n",
    "best_learner = GridSearchCV(pipeline, param_grid=parameters,cv=cv2,scoring='roc_auc',verbose=5,return_train_score=True) #GridSearchCV basically the same as cross_val_score\n",
    "best_learner.fit(X_train1, y_train1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Modelling using Xgboost \"\"\"\n",
    "'''parameters by Ehsan 'subsample': 0.8, \n",
    "              'colsample_bytree': 0.75,\n",
    "              #'min_child_weight' : 1.5,\n",
    "              'scale_pos_weight': 0.1796871962992238,\n",
    "              'objective': 'binary:logistic', \n",
    "              'lambda': 1.5,\n",
    "              'alpha': .6'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "X_train2, X_valid2, y_train2, y_valid2 = train_test_split(StandardScaler().fit_transform(add_features().transform(X_train1)), y_train1, test_size=0.30, random_state=238234)\n",
    "params = {'eta': 0.1, \n",
    "          'max_depth': 6, \n",
    "          'objective': 'binary:logistic', \n",
    "          'min_child_weight' : 6,\n",
    "          'eval_metric': 'auc',\n",
    "          'seed': 2856,\n",
    "          #'silent': True,\n",
    "          'colsample':0.8}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.frame.DataFrame, numpy.ndarray)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train1),type(X_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after train_test_split Dataframe->ndarray now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.61423\tvalid-auc:0.607894\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 20 rounds.\n",
      "[10]\ttrain-auc:0.637873\tvalid-auc:0.622925\n",
      "[20]\ttrain-auc:0.643867\tvalid-auc:0.626459\n",
      "[30]\ttrain-auc:0.651866\tvalid-auc:0.629526\n",
      "[40]\ttrain-auc:0.661038\tvalid-auc:0.631853\n",
      "[50]\ttrain-auc:0.66816\tvalid-auc:0.633329\n",
      "[60]\ttrain-auc:0.674749\tvalid-auc:0.634756\n",
      "[70]\ttrain-auc:0.679244\tvalid-auc:0.635466\n",
      "[80]\ttrain-auc:0.684926\tvalid-auc:0.636321\n",
      "[90]\ttrain-auc:0.689219\tvalid-auc:0.636754\n",
      "[100]\ttrain-auc:0.69293\tvalid-auc:0.6368\n",
      "[110]\ttrain-auc:0.69755\tvalid-auc:0.637249\n",
      "[120]\ttrain-auc:0.700636\tvalid-auc:0.636842\n",
      "[130]\ttrain-auc:0.705116\tvalid-auc:0.637305\n",
      "[140]\ttrain-auc:0.708729\tvalid-auc:0.638037\n",
      "[150]\ttrain-auc:0.711966\tvalid-auc:0.638295\n",
      "[160]\ttrain-auc:0.714999\tvalid-auc:0.638392\n",
      "[170]\ttrain-auc:0.718973\tvalid-auc:0.638477\n",
      "[180]\ttrain-auc:0.722081\tvalid-auc:0.638415\n",
      "[190]\ttrain-auc:0.725085\tvalid-auc:0.638256\n",
      "[200]\ttrain-auc:0.728081\tvalid-auc:0.638582\n",
      "[210]\ttrain-auc:0.730884\tvalid-auc:0.638439\n",
      "[220]\ttrain-auc:0.733309\tvalid-auc:0.638652\n",
      "[230]\ttrain-auc:0.737072\tvalid-auc:0.638917\n",
      "[240]\ttrain-auc:0.739507\tvalid-auc:0.639088\n",
      "[250]\ttrain-auc:0.743007\tvalid-auc:0.639598\n",
      "[260]\ttrain-auc:0.745598\tvalid-auc:0.639645\n",
      "[270]\ttrain-auc:0.747672\tvalid-auc:0.639628\n",
      "[280]\ttrain-auc:0.750866\tvalid-auc:0.639683\n",
      "[290]\ttrain-auc:0.753248\tvalid-auc:0.639896\n",
      "[300]\ttrain-auc:0.756673\tvalid-auc:0.640076\n",
      "[310]\ttrain-auc:0.759812\tvalid-auc:0.640282\n",
      "[320]\ttrain-auc:0.761792\tvalid-auc:0.639946\n",
      "Stopping. Best iteration:\n",
      "[309]\ttrain-auc:0.759413\tvalid-auc:0.640282\n",
      "\n"
     ]
    }
   ],
   "source": [
    "watchlist = [(xgb.DMatrix(X_train2, y_train2), 'train'), (xgb.DMatrix(X_valid2, y_valid2), 'valid')]\n",
    "model = xgb.train(params, xgb.DMatrix(X_train2, y_train2), 1000,  watchlist, verbose_eval=10, early_stopping_rounds=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('best score is {}'.format(best_learner.best_score_))\n",
    "#predictions=best_learner.predict(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(xgb.DMatrix(StandardScaler().fit_transform(add_features().transform(X_test1))), ntree_limit=model.best_ntree_limit)\n",
    "my_submission = pd.DataFrame({'id': X_test1['id'], 'project_is_approved': predictions})\n",
    "my_submission.to_csv('xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>project_is_approved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p233245</td>\n",
       "      <td>0.913966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p096795</td>\n",
       "      <td>0.889631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p236235</td>\n",
       "      <td>0.668938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p233680</td>\n",
       "      <td>0.780085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p171879</td>\n",
       "      <td>0.783047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>p016071</td>\n",
       "      <td>0.848914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>p099906</td>\n",
       "      <td>0.852982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>p200236</td>\n",
       "      <td>0.825959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>p129452</td>\n",
       "      <td>0.890824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>p186652</td>\n",
       "      <td>0.953506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>p257992</td>\n",
       "      <td>0.873603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>p055177</td>\n",
       "      <td>0.861770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>p069502</td>\n",
       "      <td>0.776366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>p099455</td>\n",
       "      <td>0.917444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>p226195</td>\n",
       "      <td>0.810910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>p048432</td>\n",
       "      <td>0.886575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>p028074</td>\n",
       "      <td>0.903403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>p188220</td>\n",
       "      <td>0.766961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>p213507</td>\n",
       "      <td>0.889278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>p006068</td>\n",
       "      <td>0.846000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>p124112</td>\n",
       "      <td>0.843610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>p190450</td>\n",
       "      <td>0.862730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>p180156</td>\n",
       "      <td>0.882294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>p025868</td>\n",
       "      <td>0.790181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>p134875</td>\n",
       "      <td>0.847447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>p169259</td>\n",
       "      <td>0.882155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>p124445</td>\n",
       "      <td>0.804048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>p090153</td>\n",
       "      <td>0.876538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>p086796</td>\n",
       "      <td>0.896417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>p101412</td>\n",
       "      <td>0.921129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78005</th>\n",
       "      <td>p008366</td>\n",
       "      <td>0.865356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78006</th>\n",
       "      <td>p109287</td>\n",
       "      <td>0.937598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78007</th>\n",
       "      <td>p256255</td>\n",
       "      <td>0.946466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78008</th>\n",
       "      <td>p147406</td>\n",
       "      <td>0.874098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78009</th>\n",
       "      <td>p207763</td>\n",
       "      <td>0.698559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78010</th>\n",
       "      <td>p235994</td>\n",
       "      <td>0.871613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78011</th>\n",
       "      <td>p165172</td>\n",
       "      <td>0.822107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78012</th>\n",
       "      <td>p118077</td>\n",
       "      <td>0.864712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78013</th>\n",
       "      <td>p130203</td>\n",
       "      <td>0.951014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78014</th>\n",
       "      <td>p241412</td>\n",
       "      <td>0.892715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78015</th>\n",
       "      <td>p012774</td>\n",
       "      <td>0.845725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78016</th>\n",
       "      <td>p005622</td>\n",
       "      <td>0.957702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78017</th>\n",
       "      <td>p033115</td>\n",
       "      <td>0.888903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78018</th>\n",
       "      <td>p148765</td>\n",
       "      <td>0.796226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78019</th>\n",
       "      <td>p227621</td>\n",
       "      <td>0.890246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78020</th>\n",
       "      <td>p146661</td>\n",
       "      <td>0.907708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78021</th>\n",
       "      <td>p031588</td>\n",
       "      <td>0.869244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78022</th>\n",
       "      <td>p057048</td>\n",
       "      <td>0.915011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78023</th>\n",
       "      <td>p085641</td>\n",
       "      <td>0.866506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78024</th>\n",
       "      <td>p056577</td>\n",
       "      <td>0.822807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78025</th>\n",
       "      <td>p180965</td>\n",
       "      <td>0.884102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78026</th>\n",
       "      <td>p086706</td>\n",
       "      <td>0.780519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78027</th>\n",
       "      <td>p007537</td>\n",
       "      <td>0.895255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78028</th>\n",
       "      <td>p135892</td>\n",
       "      <td>0.847114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78029</th>\n",
       "      <td>p089840</td>\n",
       "      <td>0.780310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78030</th>\n",
       "      <td>p183993</td>\n",
       "      <td>0.906023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78031</th>\n",
       "      <td>p116343</td>\n",
       "      <td>0.806285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78032</th>\n",
       "      <td>p210728</td>\n",
       "      <td>0.861900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78033</th>\n",
       "      <td>p060531</td>\n",
       "      <td>0.963702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78034</th>\n",
       "      <td>p087783</td>\n",
       "      <td>0.835602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78035 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  project_is_approved\n",
       "0      p233245             0.913966\n",
       "1      p096795             0.889631\n",
       "2      p236235             0.668938\n",
       "3      p233680             0.780085\n",
       "4      p171879             0.783047\n",
       "5      p016071             0.848914\n",
       "6      p099906             0.852982\n",
       "7      p200236             0.825959\n",
       "8      p129452             0.890824\n",
       "9      p186652             0.953506\n",
       "10     p257992             0.873603\n",
       "11     p055177             0.861770\n",
       "12     p069502             0.776366\n",
       "13     p099455             0.917444\n",
       "14     p226195             0.810910\n",
       "15     p048432             0.886575\n",
       "16     p028074             0.903403\n",
       "17     p188220             0.766961\n",
       "18     p213507             0.889278\n",
       "19     p006068             0.846000\n",
       "20     p124112             0.843610\n",
       "21     p190450             0.862730\n",
       "22     p180156             0.882294\n",
       "23     p025868             0.790181\n",
       "24     p134875             0.847447\n",
       "25     p169259             0.882155\n",
       "26     p124445             0.804048\n",
       "27     p090153             0.876538\n",
       "28     p086796             0.896417\n",
       "29     p101412             0.921129\n",
       "...        ...                  ...\n",
       "78005  p008366             0.865356\n",
       "78006  p109287             0.937598\n",
       "78007  p256255             0.946466\n",
       "78008  p147406             0.874098\n",
       "78009  p207763             0.698559\n",
       "78010  p235994             0.871613\n",
       "78011  p165172             0.822107\n",
       "78012  p118077             0.864712\n",
       "78013  p130203             0.951014\n",
       "78014  p241412             0.892715\n",
       "78015  p012774             0.845725\n",
       "78016  p005622             0.957702\n",
       "78017  p033115             0.888903\n",
       "78018  p148765             0.796226\n",
       "78019  p227621             0.890246\n",
       "78020  p146661             0.907708\n",
       "78021  p031588             0.869244\n",
       "78022  p057048             0.915011\n",
       "78023  p085641             0.866506\n",
       "78024  p056577             0.822807\n",
       "78025  p180965             0.884102\n",
       "78026  p086706             0.780519\n",
       "78027  p007537             0.895255\n",
       "78028  p135892             0.847114\n",
       "78029  p089840             0.780310\n",
       "78030  p183993             0.906023\n",
       "78031  p116343             0.806285\n",
       "78032  p210728             0.861900\n",
       "78033  p060531             0.963702\n",
       "78034  p087783             0.835602\n",
       "\n",
       "[78035 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
